%%writefile main.py
# main.py (ë§¤í¬ë¡œ ì§€í‘œ í™•ì¥: KOSPI/KOSDAQ/SP500/NASDAQ/USD-KRW/WTI/Gold/VIX/DollarIndex)
from __future__ import annotations

import importlib
import importlib.util
import json
import subprocess
import sys
from dataclasses import dataclass
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Callable, Iterable, Optional

pd: Any | None = None
requests_module: Any | None = None
stock: Any | None = None
yf: Any | None = None  # yfinance

DATA_DIR = Path("data")


@dataclass(frozen=True)
class APIEndpoint:
    name: str
    url: str
    params: Optional[dict[str, Any]] = None
    description: str = ""
    transform: Optional[Callable[[Any], Any]] = None


def ensure_packages() -> None:
    """Colab/ë¡œì»¬ ì–´ë””ì„œë“  í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ë³´ì¥"""
    global pd, requests_module, stock, yf

    required = {
        "pandas": "pandas",
        "requests": "requests",
        "pykrx": "pykrx",
        "yfinance": "yfinance",
    }

    for module_name, package_name in required.items():
        if importlib.util.find_spec(module_name) is None:
            print(f"[INFO] Installing missing package: {package_name}")
            try:
                subprocess.check_call([sys.executable, "-m", "pip", "install", package_name])
            except subprocess.CalledProcessError as exc:
                print(f"[WARN] Failed to install {package_name}: {exc}")

    pd = importlib.import_module("pandas")
    requests_module = importlib.import_module("requests")
    pykrx_module = importlib.import_module("pykrx")
    stock = getattr(pykrx_module, "stock")
    try:
        yf = importlib.import_module("yfinance")
    except ModuleNotFoundError:
        yf = None


def fetch_endpoint(endpoint: APIEndpoint) -> Any:
    assert requests_module is not None
    try:
        response = requests_module.get(endpoint.url, params=endpoint.params, timeout=15)
        response.raise_for_status()
    except requests_module.RequestException as exc:
        print(f"[ERROR] {endpoint.name}: ìš”ì²­ ì‹¤íŒ¨ - {exc}")
        return {"error": str(exc)}

    if endpoint.transform is not None:
        return endpoint.transform(response)

    content_type = response.headers.get("Content-Type", "")
    if "application/json" in content_type:
        try:
            return response.json()
        except ValueError:
            print(f"[WARN] {endpoint.name}: JSON ë””ì½”ë”© ì‹¤íŒ¨, ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return response.text
    return response.text


def save_json(data: Any, path: Path) -> None:
    with path.open("w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def ensure_directory(base: Path) -> Path:
    # UTC íƒ€ì„ìŠ¤íƒ¬í”„ í•˜ìœ„ í´ë” ìƒì„±
    ts = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
    d = base / ts
    d.mkdir(parents=True, exist_ok=True)
    return d


def collect_external_apis(endpoints: Iterable[APIEndpoint], output_dir: Path) -> None:
    for ep in endpoints:
        print(f"[INFO] Fetching {ep.name} ({ep.url})")
        data = fetch_endpoint(ep)
        save_json(data, output_dir / f"{ep.name}.json")


def _to_str_date_index(df: Any, idx_name: str = "ë‚ ì§œ") -> Any:
    """DatetimeIndex â†’ YYYYMMDD ë¬¸ìì—´ ì¸ë±ìŠ¤ë¡œ ì •ê·œí™”"""
    if df is None or getattr(df, "empty", True):
        return df
    if isinstance(df.index, pd.DatetimeIndex):
        df = df.copy()
        df.index = pd.Index([d.strftime("%Y%m%d") for d in df.index], name=idx_name)
    elif "ë‚ ì§œ" in getattr(df, "columns", []):
        df = df.copy()
        df.set_index("ë‚ ì§œ", inplace=True)
    return df


def _join_outer(base: Any, other: Any) -> Any:
    if base is None or getattr(base, "empty", True):
        return other
    if other is None or getattr(other, "empty", True):
        return base
    return base.join(other, how="outer")


def _download_close_series(sym: str, start: str, end: str) -> Any:
    """yfinanceì—ì„œ Closeë§Œ ë‚´ë ¤ë°›ì•„ YYYYMMDD ì¸ë±ìŠ¤ë¡œ ë°˜í™˜"""
    df = yf.download(sym, start=start, end=end, auto_adjust=False, progress=False)
    if df is None or df.empty:
        return None
    df = df[["Close"]]
    df = _to_str_date_index(df)
    return df


def _add_macro_features_with_yfinance(combined: Any, start_date: datetime, end_date: datetime) -> Any:
    """yfinanceë¡œ ì§€ìˆ˜/í™˜ìœ¨/ì›ìì¬ ë“± ë§¤í¬ë¡œ í”¼ì²˜ë¥¼ ì¶”ê°€"""
    if yf is None:
        print("[INFO] yfinance ë¯¸ì„¤ì¹˜: ë§¤í¬ë¡œ í”¼ì²˜ ìŠ¤í‚µ")
        return combined

    s = start_date.strftime("%Y-%m-%d")
    e = end_date.strftime("%Y-%m-%d")

    # ì—¬ëŸ¬ ì‹¬ë³¼ í›„ë³´ë¥¼ ìˆœì°¨ ì‹œë„í•˜ëŠ” ì‚¬ì „ (ì²« ì„±ê³µì„ ì±„íƒ)
    symbol_candidates: dict[str, list[str]] = {
        "macro_KOSPI":  ["^KS11"],
        "macro_KOSDAQ": ["^KQ11", "^KOSDAQ"],  # ê°€ë” ì œê³µ ì•ˆ ë  ìˆ˜ ìˆì–´ í›„ë³´ ë„£ìŒ
        "macro_SP500":  ["^GSPC"],
        "macro_NASDAQ": ["^IXIC"],
        "macro_USDKRW": ["KRW=X"],             # 1 USDë‹¹ KRW
        "macro_WTI":    ["CL=F"],
        "macro_GOLD":   ["GC=F"],
        "macro_VIX":    ["^VIX"],
        # ë‹¬ëŸ¬ì¸ë±ìŠ¤: ì„ ë¬¼/í˜„ë¬¼ ì‹¬ë³¼ì´ ì§€ì—­ì— ë”°ë¼ ë‹¤ë¦„ â†’ ìˆœì°¨ ì‹œë„
        "macro_DOLLAR_INDEX": ["DX-Y.NYB", "^DXY"],
    }

    out = combined.copy() if combined is not None else pd.DataFrame()

    for col_name, candidates in symbol_candidates.items():
        success = False
        for sym in candidates:
            try:
                print(f"[INFO] yfinance {col_name} í›„ë³´ {sym} ë‹¤ìš´ë¡œë“œ")
                df = _download_close_series(sym, s, e)
                if df is None or df.empty:
                    continue
                df = df.rename(columns={"Close": col_name})
                out = _join_outer(out, df)
                success = True
                break
            except Exception as exc:
                print(f"[WARN] {col_name} ({sym}) ì‹¤íŒ¨: {exc}")
        if not success:
            print(f"[WARN] {col_name} ëª¨ë“  í›„ë³´ ì‹¤íŒ¨ â†’ ìŠ¤í‚µ")
    return out


def collect_korean_stock_data(
    ticker: str,
    days: int,
    market: str,
    investor: str,
    output_dir: Path,
) -> None:
    """pykrx + yfinance + (ë§¤í¬ë¡œì§€í‘œ) ë¥¼ í•©ì³ CSV ì €ì¥"""
    assert pd is not None and stock is not None

    today = datetime.now()
    start_date = today - timedelta(days=days)
    f_today = today.strftime("%Y%m%d")
    f_start = start_date.strftime("%Y%m%d")

    print(f"[INFO] Collecting KRX data for ticker={ticker}, period={f_start}~{f_today}")

    combined = pd.DataFrame()

    # OHLCV
    try:
        ohlcv = stock.get_market_ohlcv_by_date(f_start, f_today, ticker)
        if not ohlcv.empty:
            ohlcv.index = ohlcv.index.strftime("%Y%m%d")
            combined = ohlcv.copy()
            combined["result"] = combined["ë“±ë½ë¥ "].apply(lambda v: 1 if v >= 0 else 0)
    except Exception as exc:
        print(f"[WARN] OHLCV ì¡°íšŒ ì‹¤íŒ¨: {exc}")

    # Fundamentals
    try:
        fundamentals = stock.get_market_fundamental(f_start, f_today, ticker)
        if not fundamentals.empty:
            fundamentals.index = fundamentals.index.strftime("%Y%m%d")
            combined = combined.join(fundamentals, how="outer") if not combined.empty else fundamentals
    except Exception as exc:
        print(f"[WARN] í€ë”ë©˜í„¸ ì¡°íšŒ ì‹¤íŒ¨: {exc}")

    # ì‹œê°€ì´ì•¡/ì™¸êµ­ì¸ë³´ìœ /ê³µë§¤ë„
    extra = [
        ("ì‹œê°€ì´ì•¡", lambda: stock.get_market_cap(f_start, f_today, ticker)),
        ("ì™¸êµ­ì¸ë³´ìœ ", lambda: stock.get_exhaustion_rates_of_foreign_investment(f_start, f_today, ticker)),
        ("ê³µë§¤ë„",     lambda: stock.get_shorting_status_by_date(f_start, f_today, ticker)),
    ]
    for label, loader in extra:
        try:
            df = loader()
        except Exception as exc:
            print(f"[WARN] {label} ì¡°íšŒ ì‹¤íŒ¨: {exc}")
            continue
        if df is None or getattr(df, "empty", True):
            continue
        df = df.copy()
        if isinstance(df.index, pd.DatetimeIndex):
            df.index = df.index.strftime("%Y%m%d")
        elif "ë‚ ì§œ" in df.columns:
            df.set_index("ë‚ ì§œ", inplace=True)
        df = df.add_prefix(f"{label}_")
        combined = combined.join(df, how="outer") if not combined.empty else df

    # íˆ¬ììë³„ ìˆœë§¤ìˆ˜ (ëŠë¦´ ìˆ˜ ìˆìŒ)
    cats = [investor, "ê°œì¸", "ì™¸êµ­ì¸", "ê¸°ê´€í•©ê³„", "ê¸ˆìœµíˆ¬ì", "ë³´í—˜", "íˆ¬ì‹ ", "ì‚¬ëª¨", "ì€í–‰", "ê¸°íƒ€ê¸ˆìœµ", "ì—°ê¸°ê¸ˆ ë“±", "êµ­ê°€", "ê¸°íƒ€ë²•ì¸"]
    cats = list(dict.fromkeys([c for c in cats if c]))
    for offset in range(days):
        cur = today - timedelta(days=offset)
        cur_s = cur.strftime("%Y%m%d")
        prev_s = (cur - timedelta(days=1)).strftime("%Y%m%d")
        for c in cats:
            try:
                p = stock.get_market_net_purchases_of_equities(prev_s, cur_s, market, c)
            except Exception as exc:
                print(f"[WARN] {cur_s} {c} ìˆœë§¤ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {exc}")
                continue
            if p is None or getattr(p, "empty", True):
                continue
            if "í‹°ì»¤" in p.columns:
                row = p[p["í‹°ì»¤"].astype(str) == ticker]
            else:
                row = p[p.index.astype(str) == ticker]
            if row.empty:
                continue
            row = row.copy()
            if "í‹°ì»¤" in row.columns:
                row.drop(columns=["í‹°ì»¤"], inplace=True)
            row.rename(columns={col: f"{c}_{col}" for col in row.columns}, inplace=True)
            row["ë‚ ì§œ"] = cur_s
            row.set_index("ë‚ ì§œ", inplace=True)
            combined = combined.combine_first(row)

    # ë³´ì¡° ì†ŒìŠ¤: yfinance (ê°œë³„ ì¢…ëª©)
    if yf is not None:
        try:
            sym = f"{ticker}.KS"  # ì‚¼ì„±ì „ì
            yfd = yf.download(sym, start=start_date.strftime("%Y-%m-%d"), end=today.strftime("%Y-%m-%d"), auto_adjust=False, progress=False)
            if not yfd.empty:
                yfd.index = pd.Index([dt.strftime("%Y%m%d") for dt in yfd.index], name="ë‚ ì§œ")
                yfd = yfd.add_prefix("yfi_")
                combined = combined.join(yfd, how="outer") if not combined.empty else yfd
        except Exception as exc:
            print(f"[WARN] yfinance ì¢…ëª© ì¡°íšŒ ì‹¤íŒ¨: {exc}")

    # ğŸ”¥ ë§¤í¬ë¡œ í”¼ì²˜(ì§€ìˆ˜/í™˜ìœ¨/ì›ìì¬/VIX/ë‹¬ëŸ¬ì¸ë±ìŠ¤) ì¶”ê°€
    combined = _add_macro_features_with_yfinance(combined, start_date, today)

    # ì €ì¥
    csv_path = output_dir / f"krx_{ticker}.csv"
    combined.sort_index().to_csv(csv_path, encoding="utf-8-sig")
    print(f"[INFO] Saved KRX dataset to {csv_path}")
    print(f"[INFO] Rows={len(combined):,}, Cols={len(combined.columns):,}")


def collect_naver_finance_data(ticker: str, output_dir: Path) -> None:
    """ë„¤ì´ë²„ ê¸ˆìœµ ë¹„ê³µì‹ APIì—ì„œ ìµœê·¼ ê°€ê²© ë¦¬ìŠ¤íŠ¸"""
    assert pd is not None and requests_module is not None
    url = f"https://api.stock.naver.com/domestic/stock/{ticker}/price"
    params = {"pageSize": "200"}
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        r = requests_module.get(url, params=params, headers=headers, timeout=15)
        r.raise_for_status()
    except requests_module.RequestException as exc:
        print(f"[WARN] ë„¤ì´ë²„ ê¸ˆìœµ ì¡°íšŒ ì‹¤íŒ¨: {exc}")
        return

    try:
        payload = r.json()
    except ValueError:
        print("[WARN] ë„¤ì´ë²„ ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹˜.")
        return

    records = payload.get("data") or payload.get("datas") or payload.get("prices") or payload.get("items") if isinstance(payload, dict) else payload
    if not isinstance(records, list) or not records:
        print("[WARN] ë„¤ì´ë²„ì—ì„œ ë³€í™˜ ê°€ëŠ¥í•œ ë°ì´í„° ì—†ìŒ.")
        return

    frame = pd.DataFrame(records)
    if frame.empty:
        print("[WARN] ë„¤ì´ë²„ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ.")
        return

    if "localTradedAt" in frame.columns:
        frame.set_index("localTradedAt", inplace=True)
    elif "tradeDate" in frame.columns:
        frame.set_index("tradeDate", inplace=True)
    frame.sort_index(inplace=True)

    save_json(frame.to_dict(orient="index"), output_dir / f"naver_{ticker}.json")
    print(f"[INFO] Saved Naver Finance dataset for {ticker}")


def main() -> None:
    ensure_packages()

    # Google Drive ë§ˆìš´íŠ¸(ê°€ëŠ¥í•˜ë©´)
    try:
        from google.colab import drive
        drive.mount("/content/drive")
        print("[INFO] Google Drive mounted successfully.")
        base_dir = Path("/content/drive/MyDrive/krx_data")
    except Exception as e:
        print(f"[WARN] Google Drive mount failed: {e}")
        print("[INFO] ë¡œì»¬ data í´ë”ì— ì €ì¥í•©ë‹ˆë‹¤.")
        base_dir = Path("data")

    output_dir = ensure_directory(base_dir)

    endpoints = [
        APIEndpoint("public_apis", "https://api.publicapis.org/entries", description="Public API ë¦¬ìŠ¤íŠ¸"),
        APIEndpoint("exchange_rates_usd", "https://open.er-api.com/v6/latest/USD", description="USD ê¸°ì¤€ í™˜ìœ¨"),
        APIEndpoint("ipinfo", "https://ipinfo.io/json", description="IP ì •ë³´"),
        APIEndpoint("world_time", "https://worldtimeapi.org/api/timezone/Etc/UTC", description="ì„¸ê³„ í‘œì¤€ì‹œ"),
        APIEndpoint("github_events", "https://api.github.com/events", description="GitHub ê³µê°œ ì´ë²¤íŠ¸"),
    ]

    # ì™¸ë¶€ APIëŠ” ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
    collect_external_apis(endpoints, output_dir)

    collect_korean_stock_data(
        ticker="005930",
        days=1825,         # ì•½ 5ë…„
        market="KOSPI",
        investor="ê°œì¸",
        output_dir=output_dir,
    )

    collect_naver_finance_data("005930", output_dir)

    print(f"[INFO] ëª¨ë“  ë°ì´í„°ê°€ {output_dir} ë””ë ‰í„°ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"[INFO] Google Drive ê²½ë¡œ: {output_dir.resolve()}")
    print("[INFO] ì˜ˆì‹œ íŒŒì¼:")
    print(f" - {output_dir / 'krx_005930.csv'}")


if __name__ == "__main__":
    main()
